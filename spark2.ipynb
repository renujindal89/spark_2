{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7aa5a605-017f-4804-9c18-871b490a3826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"PYSPARK_PYTHON\"] = \"C:/Users/complere/anaconda3/envs/pyspark_env/python.exe\"\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = \"C:/Users/complere/anaconda3/envs/pyspark_env/python.exe\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4766bc98-7b5d-4b3a-918c-eba2babd40b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"test\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a82b1cff-a2a2-4b05-9a79-82e1580dae54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+\n",
      "| Name|Age|\n",
      "+-----+---+\n",
      "|  Ram| 25|\n",
      "|Shyam| 30|\n",
      "|Geeta| 28|\n",
      "+-----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = [(\"Ram\", 25), (\"Shyam\", 30), (\"Geeta\", 28)]\n",
    "df = spark.createDataFrame(data, [\"Name\", \"Age\"])\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30460350-6fd4-4513-ad52-9093bf4b6090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "aa128664-a570-4c01-9c42-53a0eb89881c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|  david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"D:\\samples_data.csv\", header=True, inferSchema=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8101ea1c-b206-4d4e-81b4-f842287fa557",
   "metadata": {},
   "outputs": [],
   "source": [
    "inferSchema=True means Spark will automatically detect the data types of each column instead of treating everything \n",
    "as text/string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ae391a33-2977-4740-8e7e-728f0e03d731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|  david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"D:\\samples_data.csv\", header=True)\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ecfa03cc-37ac-4db5-be57-7ed7c78ac33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: string (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: string (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: string (nullable = true)\n",
      " |-- join_date: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- score: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "350e7ec8-3966-46bb-b171-c0ceb26bb0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- join_date: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"D:\\samples_data.csv\", header=True ,inferSchema=True)\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4472cf3-5178-45ca-a35d-79cec8b1ad9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "When NOT needed?\n",
    "Don’t use inferSchema when\tReason\n",
    "Huge files (very large datasets)\tSlows reading because Spark scans data to detect types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "615151ad-8ef7-4bb2-b4f2-d7a844dd241b",
   "metadata": {},
   "outputs": [],
   "source": [
    "In PySpark, data types define what kind of values each column in a DataFrame can hold.​\n",
    "They are part of pyspark.sql.types module and are similar to SQL or database data types.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2af067bd-332a-45cd-a15e-9e91831f6fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, StructField, IntegerType, StringType, DoubleType, DateType\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"id\", IntegerType(), True),\n",
    "    StructField(\"name\", StringType(), True),\n",
    "    StructField(\"age\", DoubleType(), True),\n",
    "    StructField(\"gender\", StringType(), True),\n",
    "    StructField(\"salary\", DoubleType(), True),\n",
    "    StructField(\"join_date\", StringType(), True),   # if you want DateType, change here\n",
    "    StructField(\"department\", StringType(), True),\n",
    "    StructField(\"score\", DoubleType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5110b826-165f-478b-a894-d78fbaab661a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|  david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "\n",
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- join_date: string (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv(\"D:\\samples_data.csv\", header=True ,schema=schema)\n",
    "df.show()\n",
    "df.printSchema()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f1b9c2f-977b-4906-a8fd-e8c0ecfeb1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['join_date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da3eea74-6ff3-4551-b4d9-b55e378b350c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+\n",
      "| join_date|\n",
      "+----------+\n",
      "|2021-05-10|\n",
      "|2020/03/15|\n",
      "|15-07-2019|\n",
      "|        IT|\n",
      "|2022-13-01|\n",
      "|2018-11-20|\n",
      "|wrong_date|\n",
      "|2021-09-01|\n",
      "|2020/12/01|\n",
      "|2017-05-05|\n",
      "+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"join_date\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c1a75874-3e09-4592-83c0-395b5b97a369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructField('join_date', DateType(), True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#If you want join_date as Date instead of String\n",
    "# it work only if your date is in spark date format \n",
    "#format is yyyy-MM-dd\n",
    "StructField(\"join_date\", DateType(), True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea2b908-d359-4bf6-a648-0a6c11fb41bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# but if you have mixed format you explicitely tell  csv to covert this text column in to date \n",
    "CSV stores everything as text, no datatype information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "acf8610c-b3fd-4b57-87f9-be30ebbce743",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- age: double (nullable = true)\n",
      " |-- gender: string (nullable = true)\n",
      " |-- salary: double (nullable = true)\n",
      " |-- join_date: date (nullable = true)\n",
      " |-- department: string (nullable = true)\n",
      " |-- score: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import to_date, col\n",
    "\n",
    "df = df.withColumn(\"join_date\", to_date(col(\"join_date\"), \"yyyy-MM-dd\"))\n",
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "052003b0-3bae-4887-a3e4-86b2102054e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pyspark.sql.dataframe.DataFrame"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c9443c51-3bce-48eb-b4f4-450e31657089",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(id=1, name='Alice', age=25.0, gender='F', salary=50000.0, join_date=datetime.date(2021, 5, 10), department='Sales', score=88.0),\n",
       " Row(id=2, name='Bob', age=30.0, gender='M', salary=62000.0, join_date=None, department='HR', score=92.0),\n",
       " Row(id=3, name='Charlie', age=None, gender='M', salary=58000.0, join_date=None, department='IT', score=79.0)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)  # in the form of list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af19476e-18da-49c9-bb2c-049e51c65f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "checking the datatype\n",
    "select column and indexing\n",
    "check describe option\n",
    "adding column and droping column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec26fe38-ef8a-4ddd-b68c-6a948105cf69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'name', 'age', 'gender', 'salary', 'join_date', 'department', 'score']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns # df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4b96d0b4-4b8c-4e77-a6a8-b57a5e511d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('name') # df['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "605f4808-97d1-4786-8065-d3020dbfbc8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+\n",
      "|   name|\n",
      "+-------+\n",
      "|  Alice|\n",
      "|    Bob|\n",
      "|Charlie|\n",
      "|  david|\n",
      "|    Eve|\n",
      "|    Eve|\n",
      "|  Frank|\n",
      "|   NULL|\n",
      "| Grace |\n",
      "|  Henry|\n",
      "+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('name').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "970e45fd-55fc-41bf-b726-2950ea3b1dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[name: string, age: double]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(['name','age']) # df[['name','age']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5554968a-9804-4246-981c-44422085a314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----+\n",
      "|   name|  age|\n",
      "+-------+-----+\n",
      "|  Alice| 25.0|\n",
      "|    Bob| 30.0|\n",
      "|Charlie| NULL|\n",
      "|  david| 45.0|\n",
      "|    Eve| -3.0|\n",
      "|    Eve|200.0|\n",
      "|  Frank| 33.0|\n",
      "|   NULL| 29.0|\n",
      "| Grace | NULL|\n",
      "|  Henry| 41.0|\n",
      "+-------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(['name','age']).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4477576a-f7d0-404d-95df-f30b0906c6dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing will not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "122e98e4-95c9-4ccf-8bf1-f4632d7034d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('id', 'int'),\n",
       " ('name', 'string'),\n",
       " ('age', 'double'),\n",
       " ('gender', 'string'),\n",
       " ('salary', 'double'),\n",
       " ('join_date', 'string'),\n",
       " ('department', 'string'),\n",
       " ('score', 'double')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the datatype \n",
    "df.dtypes # df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4ae8b04-0bfe-4d1d-a161-24795d25de49",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[summary: string, id: string, name: string, age: string, gender: string, salary: string, join_date: string, department: string, score: string]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe() # df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc52f246-9abc-43ad-b8f8-f68ccd8331e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-----------------+-------+------------------+------+-----------------+----------+----------+-----------------+\n",
      "|summary|               id|   name|               age|gender|           salary| join_date|department|            score|\n",
      "+-------+-----------------+-------+------------------+------+-----------------+----------+----------+-----------------+\n",
      "|  count|               10|      9|                 8|     9|                8|        10|         8|                9|\n",
      "|   mean|              5.4|   NULL|              50.0|  NULL|         174500.0|      NULL|      NULL|            106.0|\n",
      "| stddev|3.025814858109391|   NULL|62.301112120319104|  NULL|333639.6687617175|      NULL|      NULL|73.25298628724974|\n",
      "|    min|                1| Grace |              -3.0|     F|          49000.0|15-07-2019|   Finance|             65.0|\n",
      "|    max|               10|  david|             200.0|  male|        1000000.0|wrong_date|   finance|            300.0|\n",
      "+-------+-----------------+-------+------------------+------+-----------------+----------+----------+-----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.describe().show() # min,max,stddev,mean,count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "883fd312-3f11-4ec5-85e4-eda3ce8d5b36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[id: int, name: string, age: double, gender: string, salary: double, join_date: date, department: string, score: double, age after two year: double]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# adding the column\n",
    "df.withColumn('age after two year',df['age']+2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28908a4d-5c7f-4c21-8ad8-eaef681dc65a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['new']=df['age']*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a46d16c5-650d-408a-a44b-f92c19377d2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+------------------+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|age after two year|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+------------------+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|              27.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|      NULL|        HR| 92.0|              32.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|      NULL|        IT| 79.0|              NULL|\n",
      "|  4|  david| 45.0|   male|     NULL|      NULL|      NULL| NULL|              47.0|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|      NULL|      NULL| 65.0|              -1.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|             202.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|      NULL|   finance| 73.0|              35.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|              31.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|      NULL|     SALES| 90.0|              NULL|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|              43.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn('age after two year',df['age']+2).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4ee17bd9-0931-41ae-b92b-f769bed38307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|      NULL|        HR| 92.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|      NULL|        IT| 79.0|\n",
      "|  4|  david| 45.0|   male|     NULL|      NULL|      NULL| NULL|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|      NULL|      NULL| 65.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|      NULL|   finance| 73.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|      NULL|     SALES| 90.0|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show() # inplace =True, df=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28937af2-7bf6-460a-b29f-b2f898f9668a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumn('age after two year',df['age']+2) # no inplace method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd395b3a-aace-4024-af9a-e1435ff3aac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+------------------+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|age after two year|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+------------------+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|              27.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|              32.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|              NULL|\n",
      "|  4|  david| 45.0|   male|     NULL|        IT|      NULL| NULL|              47.0|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|              -1.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|             202.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|              35.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|              31.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|              NULL|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|              43.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0fea2f37-70a1-4831-aba1-fef028b6330b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the column\n",
    "df=df.drop('age after two year')   #df.drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22b1ef26-8d9f-44e7-af11-871beaa4179d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "| id|   name|  age| gender|   salary| join_date|department|score|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|    Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3|Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|  david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|    Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|    Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|  Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|   NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9| Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|  Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+-------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ade3790a-f2c1-4d80-90be-bb865854d196",
   "metadata": {},
   "source": [
    "## rename the column"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846380b-2546-4d1e-a610-da4b0e115d50",
   "metadata": {},
   "source": [
    "#df.withColumnRenamed('old','new')\n",
    "df.withColumnRenamed('name','emp_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b7754e4-8b81-49c7-846c-471224c49ab4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.withColumnRenamed('name','emp_name')   # df.rename({"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c07a6be-9394-4bd8-8c7e-1e972e3fa428",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_names = {\n",
    "    \"name\": \"emp_name\",\n",
    "    \"age\": \"emp_age\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209f883f-d83d-4d9d-bb9e-72a047860234",
   "metadata": {},
   "outputs": [],
   "source": [
    "for old, new in new_names.items():   \n",
    "    df = df.withColumnRenamed(old, new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "35764eb0-f0dd-4308-8406-a16be1659d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_items([('name', 'emp_name'), ('age', 'emp_age')])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_names.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "732803c0-9c0e-4885-9b76-07f579d3de1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|emp_age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice|   25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|   30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie|   NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david|   45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve|   -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|  200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank|   33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL|   29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace |   NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry|   41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b11c024-68c4-4bb4-b179-0271f0a5426b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# other option \n",
    "df = df.withColumnRenamed(\"name\", \"emp_name\") \\\n",
    "       .withColumnRenamed(\"age\", \"emp_age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4058d-35ab-4acf-b7aa-3727f8485d6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b8a86c2e-c20c-40b2-bf3a-1e30605e63b2",
   "metadata": {},
   "source": [
    "# handling missing value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebb99d3-ec0c-4c73-a208-aeb78df24105",
   "metadata": {},
   "source": [
    "droping column # df.drop(\"colname')\n",
    "droping row\n",
    "droping with more  parameter\n",
    "handlinh missing value by mean,median,mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c462af-e509-4918-be95-4bca52b7dad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Why Handle Nulls & Duplicates?​\n",
    "Real-world data often contains missing values (nulls) and duplicate records.​\n",
    "Nulls can lead to errors or wrong analysis results.​\n",
    "PySpark provides functions to clean data efficiently.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ece2b2a-6571-4789-82ef-c38b4dae12be",
   "metadata": {},
   "outputs": [],
   "source": [
    "Handling Nulls – Functions​\n",
    "dropna() → Remove rows with null values.​\n",
    "\n",
    "fillna() → Replace null values with a default value.​\n",
    "\n",
    "na.replace() → Replace specific nulls with values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11567309-90e4-4adc-b2be-1c4a3778455a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dropna()- Remove rows with null values​\n",
    "Removes rows that contain null (missing) values.​\n",
    "Can be customized with options:​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f09f0bc5-7327-4e21-a0a6-3df4abc8c765",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2c708134-6a4b-47e8-a6aa-dfc4daa33c95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "| id|emp_name| age|gender| salary| join_date|department|score|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "|  1|   Alice|25.0|     F|50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|30.0|     M|62000.0|2020/03/15|        HR| 92.0|\n",
      "|  7|   Frank|33.0|     M|54000.0|wrong_date|   finance| 73.0|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna().show()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07b5aa2a-b4ad-49c7-b361-0f6b92a21ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "| id|emp_name| age|gender| salary| join_date|department|score|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "|  1|   Alice|25.0|     F|50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|30.0|     M|62000.0|2020/03/15|        HR| 92.0|\n",
      "|  7|   Frank|33.0|     M|54000.0|wrong_date|   finance| 73.0|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(how=\"any\", thresh=None, subset=None).show() # same as previous"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1a11e927-3ef1-42d6-a8dc-e9803f077ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "| id|emp_name| age|gender| salary| join_date|department|score|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "|  1|   Alice|25.0|     F|50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|30.0|     M|62000.0|2020/03/15|        HR| 92.0|\n",
      "|  7|   Frank|33.0|     M|54000.0|wrong_date|   finance| 73.0|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#how=\"any\" → drop row if any column has null (default).​\n",
    "\n",
    "#how=\"all\" → drop row if all columns are null.​\n",
    "\n",
    "#thresh=n → keep row if it has at least n non-null values.​\n",
    "\n",
    "#subset=[\"col1\",\"col2\"] → apply only to selected columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ab589308-b28f-4615-8542-bd1fcc33f686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|emp_age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice|   25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|   30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie|   NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david|   45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve|   -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|  200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank|   33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL|   29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace |   NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry|   41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(how=\"all\").show()       # drop only rows fully null​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "735fb21f-33c9-40a1-ae3f-b311b232fcbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d3db6eab-505b-47b4-96d1-ab0cbf1df51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|emp_age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice|   25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|   30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie|   NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david|   45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve|   -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|  200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank|   33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL|   29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace |   NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry|   41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(thresh=1).show()       # keep rows with at least 7 non-null \n",
    "# id 4 is deleted     # atleast 7 non null values should be there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ee0f17fd-75d9-4afa-b465-05f98a591d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|emp_age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice|   25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|   30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  4|   david|   45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve|   -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|  200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank|   33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL|   29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "| 10|   Henry|   41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.dropna(subset=[\"emp_age\"]).show()  # drop rows where Age is null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4c15a8f-8776-4161-a6ee-2aeaf195eb6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fillna()- Replace null values with a default\n",
    "Fills null values with constants (number, string, dict).​\n",
    "Useful when you don’t want to remove data but impute missing values.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60a42f5c-4e6b-42e3-9f8f-7a28ca5cf3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.fillna(value, subset=None)\n",
    "value can be:​\n",
    "\n",
    "Single value → applies to all columns.​\n",
    "Dict → column-wise replacement.​\n",
    "\n",
    "​subset → choose specific columns to apply. work with single value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0fbf6248-368d-443d-bc36-c3975ea93e69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|emp_age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice|   25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|   30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie|    0.0|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david|   45.0|   male|      0.0|        IT|      NULL|  0.0|\n",
      "|  5|     Eve|   -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|  200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank|   33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL|   29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace |    0.0|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry|   41.0|Unknown|      0.0|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-------+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna(0).show()                          # fill all nulls with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4da5416a-5861-4419-9c3a-a35c565cd6e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna(\"Unknown\", subset=[\"emp_name\",\"age\"]).show()  # only for Name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0dfc0e8b-49d8-492f-af43-19dad8a1ae71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| 18.0|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|     N/A| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | 18.0|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.fillna({\"age\": 18, \"emp_name\": \"N/A\"}).show() # different defaults per column​\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa834ff8-e99b-4f5b-892e-5611454268c4",
   "metadata": {},
   "outputs": [],
   "source": [
    " na.replace()- Replace specific values​\n",
    "More flexible than fillna() because it can replace any value (not just null).​\n",
    "\n",
    "Often used for data standardization.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d8a48d-84a8-43c6-81c4-7b64c76f8187",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.na.replace(to_replace, value, subset=None)​\n",
    "to_replace → list or dict of values to replace.​['N/A,NULL,unknown']\n",
    "\n",
    "value → replacement value(s).​\n",
    "\n",
    "subset → apply to selected columns.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2d47dcbc-71bd-4336-9a9e-082218c50986",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alicia| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.replace(\"Alice\", \"Alicia\").show()  # replace Alice with Alicia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1e04820-a4a0-43c7-8bbb-76a27e77f9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|  Robert| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10| Unknown| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.replace([\"Henry\", \"Bob\"], [\"Unknown\", \"Robert\"]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "dd13e3a6-b1bb-43fd-9fce-64f3bf3cd13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|  Alicia| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|   Bobby| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8|    NULL| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.na.replace({\"Alice\":\"Alicia\", \"Bob\":\"Bobby\"}).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "011e6ca5-2e4d-4c04-bcb3-da7fd07f7cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.na.fill(\"Unknown\", subset=[\"emp_name\"]) #other option \n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66c813ac-065c-4911-88bf-5b724c6e62bc",
   "metadata": {},
   "source": [
    "# Handling Duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bb46c7-2327-402b-970f-9486bb7fafd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "distinct() → Returns unique rows across all columns.​\n",
    "\n",
    "dropDuplicates([\"col1\",\"col2\"]) → Removes duplicates based on specific columns.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "25ac02fe-238e-4632-af26-2dc26ce56c5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_dist = df.distinct() #Removes duplicate rows from the DataFrame.​\n",
    "df_dist.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c5f7cd7a-f0fb-4977-bd22-861c835dfe50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+-------+-------+----------+----------+-----+\n",
      "| id|emp_name| age| gender| salary| join_date|department|score|\n",
      "+---+--------+----+-------+-------+----------+----------+-----+\n",
      "|  9|  Grace |NULL|      F|49000.0|2020/12/01|     SALES| 90.0|\n",
      "|  1|   Alice|25.0|      F|50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob|30.0|      M|62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie|NULL|      M|58000.0|15-07-2019|        IT| 79.0|\n",
      "|  5|     Eve|-3.0|      F|72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  7|   Frank|33.0|      M|54000.0|wrong_date|   finance| 73.0|\n",
      "| 10|   Henry|41.0|Unknown|   NULL|2017-05-05|        IT| 82.0|\n",
      "|  8| Unknown|29.0| FEMALE|51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  4|   david|45.0|   male|   NULL|        IT|      NULL| NULL|\n",
      "+---+--------+----+-------+-------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#dropDuplicates() \n",
    "df = df.dropDuplicates([\"emp_name\"])\n",
    "df.show()\n",
    "# Eve is deleted"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f0c6b2a-43ab-4f71-ba53-c11264a7cc43",
   "metadata": {},
   "source": [
    "# filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c75f23d-3cf7-4105-8da7-cb39a7529ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "filter() or where()- Filtering DataFrames​\n",
    "filter() or where() method is used to select rows based on a specified condition.​\n",
    "\n",
    "Both filter() and where() work the same way.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "749cf13a-40b5-4844-a5e3-35be46622a7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(df.age > 25).show()     # df[df[emp]>25]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "18bd19ad-1a8b-4eed-b483-55b9225447ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "| id|emp_name| age|gender| salary| join_date|department|score|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "|  1|   Alice|25.0|     F|50000.0|2021-05-10|     Sales| 88.0|\n",
      "+---+--------+----+------+-------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.where(df.age == 25).show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0459655a-218b-42ab-973b-90568fc2702d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Sort() or orderBy()- Sorting Data​\n",
    "sort() or orderBy() Sorts rows by one or more columns.​\n",
    "\n",
    "Default = ascending; use .desc() for descending.​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "5a3aa4db-d4f8-41b1-9c2e-fb7651e6fdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(\"age\").show()      # df.sort_value("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "7d48dcf9-ada9-4051-b9eb-246841a7c624",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(df.age.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e421fc4f-dd99-48a8-99b1-cc39da779055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"age\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "eaeecd25-693c-44f9-b385-b0f82d170207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(df.age.desc()).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4ba6cd02-9396-4689-aca1-5ee2e5bc6686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "| id|emp_name|  age| gender|   salary| join_date|department|score|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "|  1|   Alice| 25.0|      F|  50000.0|2021-05-10|     Sales| 88.0|\n",
      "|  2|     Bob| 30.0|      M|  62000.0|2020/03/15|        HR| 92.0|\n",
      "|  3| Charlie| NULL|      M|  58000.0|15-07-2019|        IT| 79.0|\n",
      "|  4|   david| 45.0|   male|     NULL|        IT|      NULL| NULL|\n",
      "|  5|     Eve| -3.0|      F|  72000.0|2022-13-01|      NULL| 65.0|\n",
      "|  5|     Eve|200.0|   NULL|1000000.0|2018-11-20|   Finance|300.0|\n",
      "|  7|   Frank| 33.0|      M|  54000.0|wrong_date|   finance| 73.0|\n",
      "|  8| Unknown| 29.0| FEMALE|  51000.0|2021-09-01|     Sales| 85.0|\n",
      "|  9|  Grace | NULL|      F|  49000.0|2020/12/01|     SALES| 90.0|\n",
      "| 10|   Henry| 41.0|Unknown|     NULL|2017-05-05|        IT| 82.0|\n",
      "+---+--------+-----+-------+---------+----------+----------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26a2b9-4789-4824-ba70-0225ff45dbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609c0355-d72f-4e9e-bfab-2aa70e77d6fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PySpark Env",
   "language": "python",
   "name": "pyspark_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.25"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
